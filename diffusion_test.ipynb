{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0200, 0.0400, 0.0600, 0.0800, 0.1000, 0.1200, 0.1400, 0.1600,\n",
      "        0.1800, 0.2000, 0.2200, 0.2400, 0.2600, 0.2800, 0.3000, 0.3200, 0.3400,\n",
      "        0.3600, 0.3800, 0.4000, 0.4200, 0.4400, 0.4600, 0.4800, 0.5000, 0.5200,\n",
      "        0.5400, 0.5600, 0.5800, 0.6000, 0.6200, 0.6400, 0.6600, 0.6800, 0.7000,\n",
      "        0.7200, 0.7400, 0.7600, 0.7800, 0.8000, 0.8200, 0.8400, 0.8600, 0.8800,\n",
      "        0.9000, 0.9200, 0.9400, 0.9600, 0.9800, 1.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "T = 50\n",
    "beta_schedule = torch.linspace(0, 1.0, T+1).to('cuda')\n",
    "\n",
    "print(beta_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_feat, out_ch):\n",
    "    if len(in_feat.size()) == 3:\n",
    "        ch, _, _ = in_feat.size()\n",
    "    else:\n",
    "        _, ch, _, _ = in_feat.size()\n",
    "\n",
    "    conv_layer = nn.Conv2d(in_channels=ch, out_channels=out_ch, kernel_size=3, stride=1, padding=1).to(in_feat.device)\n",
    "    return conv_layer(in_feat)\n",
    "\n",
    "def dense(in_feat, out_ch):\n",
    "    if len(in_feat.size()) == 2:\n",
    "        _, ch = in_feat.size()\n",
    "    else:\n",
    "        _, _, ch = in_feat.size()\n",
    "    \n",
    "    dense_layer = nn.Linear(in_features=ch, out_features=out_ch).to(in_feat.device)\n",
    "\n",
    "    return dense_layer(in_feat)\n",
    "\n",
    "class time_embedding(nn.Module):\n",
    "    def __init__(self, out_ch):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_ch = out_ch\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batchnorm = nn.BatchNorm2d(num_features=out_ch)\n",
    "\n",
    "    def forward(self, x_img, x_ts):\n",
    "        out_ch = self.out_ch\n",
    "        x_parameter = conv3x3(x_img, out_ch)\n",
    "        x_parameter = self.relu(x_parameter)\n",
    "\n",
    "        x_ts = x_ts.view(-1, 1, 1).float()\n",
    "        time_parameter = dense(x_ts, out_ch)\n",
    "        time_parameter = self.relu(time_parameter)\n",
    "        time_parameter = time_parameter.view(-1, out_ch, 1, 1)\n",
    "        x_parameter = x_parameter * time_parameter\n",
    "\n",
    "        x_out = conv3x3(x_parameter, out_ch)\n",
    "        x_out = x_out + x_parameter\n",
    "        x_out = self.batchnorm(x_out)\n",
    "        x_out = self.relu(x_out)\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_diffusion (x0, t):\n",
    "    alphas = 1. - beta_schedule\n",
    "    alpha_bars = alphas.cumprod(dim=0)\n",
    "    \n",
    "    epsilon = torch.randn_like(x0)\n",
    "\n",
    "    alpha_bar_t = torch.gather(alpha_bars, dim=0, index=t)\n",
    "    alpha_bar_t = torch.reshape(alpha_bar_t,(-1,1,1,1))\n",
    "    \n",
    "    noisy_image = torch.sqrt(alpha_bar_t)*x0 + torch.sqrt(1 - alpha_bar_t)*epsilon\n",
    "    return noisy_image, epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([4, 1, 28, 28]) torch.Size([4, 1, 28, 28])\n",
      "torch.Size([4, 192, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(size=[4, 1, 28, 28]).to('cuda')\n",
    "\n",
    "# ts = np.random.randint(0, T, size=len(x))\n",
    "ts = torch.randint(0, T, size=(len(x),), device='cuda')\n",
    "print(ts.shape)\n",
    "x_t, epsilon = forward_diffusion(x, ts)\n",
    "print(x_t.shape, epsilon.shape)\n",
    "test1 = conv3x3(x, 192).to('cuda')\n",
    "# test2 = dense(x_t, 192)\n",
    "print(test1.shape)\n",
    "# print(test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_lin = torch.randn(size=(4, ))\n",
    "# test_lin = test_lin.view(-1, 1, 1)\n",
    "# print(test_lin)\n",
    "# print(test_lin.shape)\n",
    "# tt = dense(test_lin, 192)\n",
    "\n",
    "# print(tt.shape)\n",
    "time_embedding_layer = time_embedding(192).to('cuda')\n",
    "time_test = time_embedding_layer.forward(x, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
